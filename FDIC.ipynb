{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "import re\n",
    "import fnmatch\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from datetime import date\n",
    "\n",
    "#@Param - downloadPath, Path to download raw data \n",
    "#@Param - targetPath, Path to write standardized data to be uploaded to S3 Bucket \n",
    "\n",
    "class FDIC():\n",
    "    def __init__(self,downloadPath,targetPath):\n",
    "        self.downloadTargetFolder = downloadPath\n",
    "        self.targetPath = targetPath\n",
    "    \n",
    "    # Set variable for source parent URL and the download target folder\n",
    "    sourceURL = 'https://www5.fdic.gov/sdi/Resource/AllReps/All_Reports_'\n",
    "\n",
    "    # Set variables to be use for string manipulation and declare array to hold the final source URL's\n",
    "    quarters = ['0331', '0630', '0930', '1231']\n",
    "    startingYear = 2009\n",
    "    urlList = []\n",
    "    \n",
    "\n",
    "    # Loop from starting year to current year and create a source URL for each quarter. Push URL's into final URL array.\n",
    "    def createURLArray(year):\n",
    "        while year < date.today().year:\n",
    "            for q in quarters:\n",
    "                urlList.append(sourceURL + str(year) + q + '.zip')\n",
    "            year += 1\n",
    "\n",
    "\n",
    "    # Declare function for downloading and unpacking the .zip files from source URL's to a specified target folder.\n",
    "    def GetFileFromURL(url):\n",
    "        try:\n",
    "            print(\"Downloading: \" + url)\n",
    "            sourceZip = requests.get(url)\n",
    "            zipContent = zipfile.ZipFile(io.BytesIO(sourceZip.content))\n",
    "            print(\"Unpacking files for: \" + url)\n",
    "            zipContent.extractall(downloadTargetFolder)\n",
    "        except:\n",
    "            print(\"Zip file not found at the following URL: \".format(url))\n",
    "\n",
    "    def GetBulkFiles():\n",
    "        startYear = int(input(\"Enter a starting year for the data pull: \"))\n",
    "        createURLArray(startYear)\n",
    "        for url in urlList:\n",
    "            GetFileFromURL(url)\n",
    "\n",
    "\n",
    "    def prepare_files(path):\n",
    "        \n",
    "        GetBulkFiles()\n",
    "        \n",
    "        path=path\n",
    "        os.chdir(path)\n",
    "        filelist=[]\n",
    "        dict_={}\n",
    "        startvalue=1\n",
    "\n",
    "        unique_endings=[]\n",
    "        for file in glob.glob(\"*_fs220*\"):\n",
    "            unique_endings.append(file.split(\"_\")[-1].split(\".\")[0])\n",
    "        unique_endings=set(unique_endings)\n",
    "\n",
    "\n",
    "        last_year_list=[]\n",
    "        last_month_list=[]\n",
    "        for ending in unique_endings:\n",
    "            last_year_reported='2000'\n",
    "            last_month_reported=3\n",
    "            for file in glob.glob(\"*\"+ending+'.csv'):\n",
    "                latest_year=file[0:4]\n",
    "                latest_year_int=int(latest_year)\n",
    "                if latest_year_int > int(last_year_reported):\n",
    "                    last_year_reported = str(latest_year_int)\n",
    "            last_year_list.append(last_year_reported)\n",
    "            for file in glob.glob(last_year_reported+\"*\"+ending+'.csv'):\n",
    "                    latest_month=file[4:6]\n",
    "                    len_s=len(latest_month)\n",
    "                    latest_month_int=int(latest_month)\n",
    "                    if latest_month_int > int(last_month_reported):\n",
    "                        last_month_reported = str(latest_month_int).rjust(len_s, \"0\")\n",
    "                        last_month_list.append(last_month_reported)\n",
    "\n",
    "\n",
    "        for ending,year,month in zip(unique_endings, last_year_list, last_month_list):\n",
    "            #print(year,month,ending)\n",
    "            latest_csv=pd.read_csv(path+year+month+'_'+ending+'.csv', encoding='latin1', dtype=object)#/most_recent+ending\n",
    "            latest_csv.columns=map(str.upper, latest_csv.columns)\n",
    "            latest_vars=latest_csv.columns.tolist()\n",
    "\n",
    "            for file in glob.glob(\"*_\"+ending+\".csv\"):#200903_fs220.csv\n",
    "                filename = file[:-4]\n",
    "                filelist.append(filename)\n",
    "                dict_[filename] = pd.read_csv(file, encoding='latin1', dtype=object)\n",
    "                dict_[filename].columns = map(str.upper, dict_[filename].columns)\n",
    "                set1=dict_[filename].columns.tolist()\n",
    "                set2=latest_vars\n",
    "                to_add=[x for x in set2 if x not in set1]\n",
    "                columns=dict_[filename].columns.tolist()\n",
    "                dict_[filename]=dict_[filename].reindex(columns=[*dict_[filename].columns.tolist(), *to_add], fill_value='nan')\n",
    "                dict_[filename]=dict_[filename].reindex_axis(columns+to_add, axis=1)\n",
    "                dict_[filename].insert(0, 'ORDERS', range(startvalue, startvalue + len(dict_[filename])))\n",
    "                startvalue+=len(dict_[filename])\n",
    "                dict_[filename].insert(1, 'CU_NUM_DATE', dict_[filename]['CU_NUMBER'].astype(str)+'_'+pd.to_datetime(dict_[filename]['CYCLE_DATE']).dt.date.astype(str))\n",
    "                dict_[filename].insert(2, 'QUARTER', filename[4:6])\n",
    "                dict_[filename].insert(3, 'YEAR', filename[:-8])\n",
    "        return dict_\n",
    "    \n",
    "    #Target Path to put standardized data\n",
    "    def standardizeData():\n",
    "        FDICdict_=prepare_files(path)\n",
    "        #Writes\n",
    "        for key in dict_.keys():\n",
    "            FDICdict_[key].to_csv(targetPath+'/{}.csv'.format(key.split(\"_\")[-1]+'-csv.'+key), index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataType(val, current_type):\n",
    "    try:\n",
    "        # Evaluates numbers to an appropriate type, and strings an error\n",
    "        t = ast.literal_eval(val)\n",
    "    except ValueError:\n",
    "        return 'varchar'\n",
    "    except SyntaxError:\n",
    "        return 'varchar'\n",
    "    if type(t) in [int, float]:\n",
    "        if type(t) is int and current_type not in ['varchar']:\n",
    "            return 'decimal'\n",
    "        else: \n",
    "            return'varchar'\n",
    "    else:\n",
    "        return 'varchar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTable(recentFile, ending):\n",
    "    \n",
    "    f = open(recentFile, 'r')#.read().split('\\n')\n",
    "    reader = csv.reader(f)\n",
    "    longest, headers, type_list = [], [], []\n",
    "  #  headers = features\n",
    "  #  for x in headers:\n",
    "    #    longest.append(0)\n",
    "     #   type_list.append('')\n",
    "    \n",
    "    firstLine = True\n",
    "    for row in reader:\n",
    "        if firstLine:\n",
    "            firstLine = False\n",
    "        if len(headers) == 0:\n",
    "            headers = row\n",
    "            for col in row:\n",
    "                longest.append(0)\n",
    "                type_list.append('')\n",
    "        else:\n",
    "            for i in range(len(row)):\n",
    "            # NA is the csv null value\n",
    "                if type_list[i] == 'varchar' or row[i] == 'NA':\n",
    "                    pass\n",
    "                else:\n",
    "                    var_type = dataType(row[i], type_list[i])\n",
    "                    #print(var_type)\n",
    "                    \n",
    "                    type_list[i] = var_type\n",
    "            if len(row[i]) > longest[i]:\n",
    "                longest[i] = len(row[i])\n",
    "        #f.close()\n",
    "\n",
    "    statement = 'create table {} ( \\n'.format(ending)\n",
    "\n",
    "    for i in range(len(headers)):\n",
    "        if type_list[i] == 'varchar':\n",
    "            statement = (statement + '{} varchar(255), \\n').format(headers[i].upper())\n",
    "            \n",
    "        else:\n",
    "            statement = (statement + '{} {}' + ', \\n').format(headers[i].upper(), type_list[i])\n",
    "    print(statement)\n",
    "    return statement[:-3] + ');'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloads and standardizes FDIC data\n",
    "fdic = FDIC(downloadPath='',targetPath='')\n",
    "fdic.standardizeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
